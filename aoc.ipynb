{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General imports and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from functools import lru_cache, cache\n",
    "import itertools\n",
    "\n",
    "DATA_ROOT = Path(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = DATA_ROOT / 'day_1' / 'full.txt'\n",
    "contents = np.genfromtxt(file, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1941353"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents[:, 0].sort()\n",
    "contents[:, 1].sort()\n",
    "np.abs(np.diff(contents, axis=1)).sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22539317"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers, counts = np.unique(contents[:, 1], return_counts=True)\n",
    "occurences = dict(zip(numbers, counts))\n",
    "s = np.sum(contents[:, 0] * np.vectorize(lambda x: occurences.get(x, 0))(contents[:, 0]))\n",
    "s.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = DATA_ROOT / 'day_2' / 'full.txt'\n",
    "contents = [[int(x) for x in l.split()] for l in open(file, 'r').readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "332"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 0\n",
    "for report in contents:\n",
    "    report = np.array(report)\n",
    "    ascending = np.all(report[:-1] <= report[1:])\n",
    "    descending = np.all(report[:-1] >= report[1:])\n",
    "    differences = np.abs(np.diff(report))\n",
    "    level_changes = (differences.min() >= 1) & (differences.max() <= 3)\n",
    "    s += (ascending | descending) & level_changes\n",
    "s.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_report(report):\n",
    "    ascending = np.all(report[:-1] <= report[1:])\n",
    "    descending = np.all(report[:-1] >= report[1:])\n",
    "    differences = np.abs(np.diff(report))\n",
    "    level_changes = (differences.min() >= 1) & (differences.max() <= 3)\n",
    "    return (ascending | descending) & level_changes\n",
    "\n",
    "s = 0\n",
    "for report in contents:\n",
    "    report = np.array(report)\n",
    "    if check_report(report):\n",
    "        s += 1\n",
    "    else:\n",
    "        for i in range(len(report)):\n",
    "            if check_report(np.concatenate((report[:i], report[i + 1:]))):\n",
    "                s += 1\n",
    "                break\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = DATA_ROOT / 'day_3' / 'full.txt'\n",
    "contents = ''.join(open(file, 'r').readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((int(s.split(',')[0][4:]) * int(s.split(',')[1][:-1]) for s in re.findall(r'mul\\(\\d{1,3},\\d{1,3}\\)', contents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76911921"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = re.findall(r'mul\\(\\d{1,3},\\d{1,3}\\)|do\\(\\)|don\\'t\\(\\)', contents)\n",
    "enabled = True\n",
    "s = 0\n",
    "for match in matches:\n",
    "    if match == 'do()':\n",
    "        enabled = True\n",
    "    elif match == 'don\\'t()':\n",
    "        enabled = False\n",
    "    elif enabled:\n",
    "        s += int(match.split(',')[0][4:]) * int(match.split(',')[1][:-1])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_word(arr, row, col, word='XMAS'):\n",
    "    nrows, ncols = arr.shape\n",
    "    word_size = len(word)\n",
    "    word = np.array(list(word))\n",
    "    word_backwards = word[::-1]\n",
    "\n",
    "    count = 0\n",
    "    if col <= nrows - word_size:\n",
    "        hor_subword = arr[row, col:col + word_size]\n",
    "        if  np.array_equal(hor_subword, word) or np.array_equal(hor_subword, word_backwards):\n",
    "            count += 1\n",
    "        \n",
    "    if row <= ncols - word_size:\n",
    "        vert_subword = arr[row:row + word_size, col]\n",
    "        if np.array_equal(vert_subword, word) or np.array_equal(vert_subword, word_backwards):\n",
    "            count += 1\n",
    "\n",
    "    if row <= nrows - word_size and col <= ncols - word_size:\n",
    "        diag_subword = np.diagonal(arr[row: row + word_size, col: col + word_size])\n",
    "        if np.array_equal(diag_subword, word) or np.array_equal(diag_subword, word_backwards):\n",
    "            count += 1\n",
    "\n",
    "    if row >= word_size - 1 and col <= ncols - word_size:\n",
    "        diag_subword = np.diagonal(np.fliplr(arr[row - word_size + 1: row + 1, col: col + word_size]))\n",
    "        if np.array_equal(diag_subword, word) or np.array_equal(diag_subword, word_backwards):\n",
    "            count += 1\n",
    "\n",
    "    return count\n",
    "\n",
    "def check_cross(arr, row, col):\n",
    "    if arr[row, col] != 'A':\n",
    "        return False\n",
    "    tl = arr[row - 1, col - 1]\n",
    "    tr = arr[row - 1, col + 1]\n",
    "    bl = arr[row + 1, col - 1]\n",
    "    br = arr[row + 1, col + 1]\n",
    "    return  ((tl == 'M' and br == 'S') or (tl == 'S' and br == 'M')) \\\n",
    "        and ((bl == 'M' and tr == 'S') or (bl == 'S' and tr == 'M'))\n",
    "\n",
    "file = DATA_ROOT / 'day_4' / 'full.txt'\n",
    "contents = np.genfromtxt(file, dtype=str, delimiter=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2578"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrows, ncols = contents.shape\n",
    "np.sum([[check_word(contents, row, col) for col in range(ncols)] for row in range(nrows)]).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1972"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrows, ncols = contents.shape\n",
    "np.sum([[check_cross(contents, row, col) for col in range(1, ncols - 1)] for row in range(1, nrows - 1)]).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = DATA_ROOT / 'day_5' / 'full.txt'\n",
    "contents = open(file, 'r').read()\n",
    "\n",
    "rules, printing_orders = contents.split('\\n\\n')\n",
    "before_dict = defaultdict(set)\n",
    "for rule in rules.split():\n",
    "    before, after = map(int, rule.split('|'))\n",
    "    before_dict[after].add(before)\n",
    "printing_orders = [list(map(int, order.split(','))) for order in printing_orders.split()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5639"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_valid_order(order):\n",
    "    for i, current_page in enumerate(order[:-1]):\n",
    "        if any(next_page in before_dict[current_page] for next_page in order[i + 1:]):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "sum(order[len(order) // 2] for order in [order for order in printing_orders if is_valid_order(order)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5273"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "changed_orders = []\n",
    "for order in printing_orders:\n",
    "    order = order[:]\n",
    "    changed = False\n",
    "    for i in range(len(order) - 1):\n",
    "        current_page = order[i]\n",
    "        for j in range(i + 1, len(order)):\n",
    "            next_page = order[j]\n",
    "            if next_page in before_dict[current_page]:\n",
    "                order[i] = next_page\n",
    "                order[j] = current_page\n",
    "                current_page = next_page\n",
    "                changed = True\n",
    "    if changed:\n",
    "        changed_orders.append(order)\n",
    "sum([order[len(order) // 2] for order in changed_orders])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "rot = np.array([[0, 1], [-1, 0]])\n",
    "\n",
    "\n",
    "def get_config(file):\n",
    "    grid = {}\n",
    "    guard_pos = None\n",
    "    guard_orientation = None\n",
    "    for row, line in enumerate(open(file, 'r').readlines()):\n",
    "        for col, cell in enumerate(line):\n",
    "            grid[(row, col)] = '.'\n",
    "            if cell == '#':\n",
    "                grid[(row, col)] = '#'\n",
    "            elif cell == '^':\n",
    "                guard_pos = np.array([row, col])\n",
    "                guard_orientation = np.array([-1, 0])\n",
    "            elif cell == '>':\n",
    "                guard_pos = np.array([row, col])\n",
    "                guard_orientation = np.array([0, 1])\n",
    "            elif cell == 'v':\n",
    "                guard_pos = np.array([row, col])\n",
    "                guard_orientation = np.array([1, 0])\n",
    "            elif cell == '<':\n",
    "                guard_pos = np.array([row, col])\n",
    "                guard_orientation = np.array([0, -1])\n",
    "    return grid, guard_pos, guard_orientation\n",
    "\n",
    "\n",
    "def get_visited_squares(grid, guard_pos, guard_orientation):\n",
    "    visited_squares = set([tuple(guard_pos.tolist())])\n",
    "    next_pos = guard_pos + guard_orientation\n",
    "    next_pos_tuple = tuple(next_pos.tolist())\n",
    "    while next_pos_tuple in grid:\n",
    "        if grid[next_pos_tuple] == '#':\n",
    "            guard_orientation = rot @ guard_orientation\n",
    "        else:\n",
    "            visited_squares.add(next_pos_tuple)\n",
    "            guard_pos = next_pos\n",
    "        next_pos = guard_pos + guard_orientation\n",
    "        next_pos_tuple = tuple(next_pos.tolist())\n",
    "    return visited_squares\n",
    "\n",
    "\n",
    "file = DATA_ROOT / 'day_6' / 'full.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4696"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visited_squares = get_visited_squares(*get_config(file))\n",
    "len(visited_squares)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1443"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_grid(grid, guard_pos, guard_orientation):\n",
    "    guard_configs = set([tuple(guard_pos.tolist() + guard_orientation.tolist())])\n",
    "    next_pos = guard_pos + guard_orientation\n",
    "    next_pos_tuple = tuple(next_pos.tolist())\n",
    "    next_guard_tuple = tuple(next_pos.tolist() + guard_orientation.tolist())\n",
    "    while next_pos_tuple in grid and not next_guard_tuple in guard_configs:\n",
    "        if grid[next_pos_tuple] == '#':\n",
    "            guard_orientation = rot @ guard_orientation\n",
    "        else:\n",
    "            guard_configs.add(next_guard_tuple)\n",
    "            guard_pos = next_pos\n",
    "        next_pos = guard_pos + guard_orientation\n",
    "        next_pos_tuple = tuple(next_pos.tolist())\n",
    "        next_guard_tuple = tuple(next_pos.tolist() + guard_orientation.tolist())\n",
    "    return next_guard_tuple in guard_configs\n",
    "\n",
    "\n",
    "grid, guard_pos, guard_orientation = get_config(file)\n",
    "visited_squares = get_visited_squares(grid, guard_pos, guard_orientation)\n",
    "visited_squares.remove(tuple(guard_pos.tolist()))\n",
    "\n",
    "suitable_locations = 0\n",
    "for potential_location in visited_squares:\n",
    "    modified_grid = dict(grid)\n",
    "    modified_grid[potential_location] = '#'\n",
    "    if check_grid(modified_grid, guard_pos, guard_orientation):\n",
    "        suitable_locations += 1\n",
    "suitable_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = DATA_ROOT / 'day_7' / 'full.txt'\n",
    "calibration_list = [[int(calibration_value)] + list(map(int, numbers.split())) for calibration_value, numbers in map(lambda x: x.split(': '), open(file, 'r').readlines())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12839601725877\n"
     ]
    }
   ],
   "source": [
    "@lru_cache(maxsize=int(2**16))\n",
    "def check_calibration(calibration_value, numbers, current_value):\n",
    "    if not numbers:\n",
    "        return current_value == calibration_value\n",
    "    if current_value > calibration_value:\n",
    "        return False\n",
    "    \n",
    "    return check_calibration(calibration_value, numbers[1:], current_value + numbers[0]) \\\n",
    "        or check_calibration(calibration_value, numbers[1:], current_value * numbers[0])\n",
    "\n",
    "sum([l[0] for l in calibration_list if check_calibration(l[0], tuple(l[2:]), l[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149956401519484\n"
     ]
    }
   ],
   "source": [
    "@lru_cache(maxsize=int(2**16))\n",
    "def check_calibration(calibration_value, numbers, current_value):\n",
    "    if not numbers:\n",
    "        return current_value == calibration_value\n",
    "    if current_value > calibration_value:\n",
    "        return False\n",
    "    \n",
    "    return check_calibration(calibration_value, numbers[1:], current_value + numbers[0]) \\\n",
    "        or check_calibration(calibration_value, numbers[1:], current_value * numbers[0]) \\\n",
    "        or check_calibration(calibration_value, numbers[1:], int(str(current_value) + str(numbers[0])))\n",
    "\n",
    "sum([l[0] for l in calibration_list if check_calibration(l[0], tuple(l[2:]), l[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = DATA_ROOT / 'day_8' / 'full.txt'\n",
    "\n",
    "lines = open(file, 'r').readlines()\n",
    "grid = {}\n",
    "nodes = defaultdict(list)\n",
    "for row, line in enumerate(lines):\n",
    "    for col, cell in enumerate(line.strip()):\n",
    "        grid[(row, col)] = cell\n",
    "        if cell != '.':\n",
    "            nodes[cell].append(np.array([row, col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "antinode_locations = set()\n",
    "for node in nodes:\n",
    "    for node_0, node_1 in itertools.combinations(nodes[node], 2):\n",
    "        diff = node_0 - node_1\n",
    "        antinode_0 = tuple((node_1 + 2 * diff).tolist())\n",
    "        antinode_1 = tuple((node_0 - 2 * diff).tolist())\n",
    "        if antinode_0 in grid:\n",
    "            antinode_locations.add(antinode_0)\n",
    "        if antinode_1 in grid:\n",
    "            antinode_locations.add(antinode_1)\n",
    "len(antinode_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "934"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "antinode_locations = set()\n",
    "for node in nodes:\n",
    "    for node_0, node_1 in itertools.combinations(nodes[node], 2):\n",
    "        diff = node_0 - node_1\n",
    "        i = 0\n",
    "        while True:\n",
    "            i += 1\n",
    "            antinode_0 = tuple((node_1 + i * diff).tolist())\n",
    "            antinode_1 = tuple((node_0 - i * diff).tolist())\n",
    "            if antinode_0 in grid:\n",
    "                antinode_locations.add(antinode_0)\n",
    "            if antinode_1 in grid:\n",
    "                antinode_locations.add(antinode_1)\n",
    "            if antinode_0 not in grid and antinode_1 not in grid:\n",
    "                break\n",
    "        \n",
    "len(antinode_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_checksum(disk):\n",
    "    disk = disk.copy()\n",
    "    disk[disk < 0] = 0\n",
    "    return (disk * np.arange(len(disk))).sum().item()\n",
    "\n",
    "\n",
    "file = DATA_ROOT / 'day_9' / 'full.txt'\n",
    "\n",
    "contents = [int(x) for x in open(file, 'r').read()]\n",
    "disk = []\n",
    "for i, x in enumerate(contents):\n",
    "    if i % 2 == 0:\n",
    "        disk += [i // 2] * x\n",
    "    else:\n",
    "        disk += [-1] * x\n",
    "disk = np.array(disk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6337921897505"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disk_c = disk.copy()\n",
    "empty_spaces = np.nonzero(disk_c < 0)[0]\n",
    "filled_spaces = np.nonzero(disk_c >= 0)[0][::-1]\n",
    "i = 0\n",
    "while np.nonzero(disk_c < 0)[0][0] < len(filled_spaces):\n",
    "    disk_c[empty_spaces[i]] = disk_c[filled_spaces[i]]\n",
    "    disk_c[filled_spaces[i]] = -1\n",
    "    i += 1\n",
    "calculate_checksum(disk_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6362722604045"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_empty_runs(disk):\n",
    "    empty_spaces = np.nonzero(disk < 0)[0]\n",
    "    run_start = empty_spaces[0]\n",
    "    run_length = 1\n",
    "    runs = []\n",
    "    for current, next in zip(empty_spaces[:-1], empty_spaces[1:]):\n",
    "        if next - current == 1:\n",
    "            run_length += 1\n",
    "        else:\n",
    "            runs.append([run_start.item(), run_length])\n",
    "            run_start = next\n",
    "            run_length = 1\n",
    "    runs.append([run_start.item(), run_length])\n",
    "    return runs\n",
    "\n",
    "\n",
    "disk_c = disk.copy()\n",
    "empty_runs = get_empty_runs(disk_c)\n",
    "max_file_id = disk_c.max()\n",
    "for file_id in range(max_file_id, -1, -1):\n",
    "    file_length = sum(disk_c == file_id).item()\n",
    "    file_start = np.nonzero(disk_c == file_id)[0][0]\n",
    "    for i, (run_start, run_length) in enumerate(empty_runs):\n",
    "        if run_length >= file_length and run_start < file_start:\n",
    "            disk_c[disk_c == file_id] = -1\n",
    "            disk_c[run_start: run_start + file_length] = file_id\n",
    "            empty_runs[i][0] += file_length\n",
    "            empty_runs[i][1] -= file_length\n",
    "            break\n",
    "calculate_checksum(disk_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = DATA_ROOT / 'day_10' / 'full.txt'\n",
    "\n",
    "contents = np.genfromtxt(file, delimiter=1, dtype=np.int32)\n",
    "x, y = np.nonzero(contents == 0)\n",
    "trailheads = [(row, col) for row, col in zip(x.tolist(), y.tolist())]\n",
    "top_map = {(row, col): contents[row, col].item() for row, col in itertools.product(range(len(contents)), range(len(contents[0])))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "548"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@cache\n",
    "def get_trailhead_score(row, col, prev_value):\n",
    "    current_value = top_map.get((row, col), -1)\n",
    "    if current_value != prev_value + 1:\n",
    "        return set()\n",
    "    if current_value == 9:\n",
    "        return {(row, col)}\n",
    "    return get_trailhead_score(row + 1, col, current_value) \\\n",
    "    | get_trailhead_score(row - 1, col, current_value) \\\n",
    "    | get_trailhead_score(row, col + 1, current_value) \\\n",
    "    | get_trailhead_score(row, col - 1, current_value)\n",
    "\n",
    "sum([len(get_trailhead_score(row, col, -1)) for row, col in trailheads])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1252"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@cache\n",
    "def get_trailhead_score(row, col, prev_value):\n",
    "    current_value = top_map.get((row, col), -1)\n",
    "    if current_value != prev_value + 1:\n",
    "        return 0\n",
    "    if current_value == 9:\n",
    "        return 1\n",
    "    return get_trailhead_score(row + 1, col, current_value) \\\n",
    "    + get_trailhead_score(row - 1, col, current_value) \\\n",
    "    + get_trailhead_score(row, col + 1, current_value) \\\n",
    "    + get_trailhead_score(row, col - 1, current_value)\n",
    "\n",
    "sum([get_trailhead_score(row, col, -1) for row, col in trailheads])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache\n",
    "def get_stone_after_blink(stone):\n",
    "    if stone == 0:\n",
    "        return [1]\n",
    "    stone_str = str(stone)\n",
    "    stone_str_len = len(stone_str)\n",
    "    if stone_str_len % 2 == 0:\n",
    "        return [int(stone_str[:stone_str_len // 2]), int(stone_str[stone_str_len // 2:])]\n",
    "    return [stone * 2024]\n",
    "\n",
    "\n",
    "@cache\n",
    "def get_stones_after_blinking(stones, n_blinks):\n",
    "    if n_blinks == 0:\n",
    "        return len(stones)\n",
    "    \n",
    "    return sum(get_stones_after_blinking(tuple(get_stone_after_blink(stone)), n_blinks - 1) for stone in stones)\n",
    "\n",
    "\n",
    "file = DATA_ROOT / 'day_11' / 'full.txt'\n",
    "\n",
    "stones = tuple([int(x) for x in open(file, 'r').read().split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216996"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stones_after_blinking(stones, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257335372288947"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stones_after_blinking(stones, 75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
